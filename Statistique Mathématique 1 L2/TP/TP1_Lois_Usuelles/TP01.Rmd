---
title: "*TP R Statistique Mathématiques 1*"
author: | 
        **Mohamed FOFANA** |
        *L2 MIASHS - Université Grenoble Alpes*
output:
  pdf_document: 
    latex_engine: xelatex
    toc: true
    number_sections: true
  html_document: 
    toc: true
    number_sections: true
---

# Séance TP 1: Lois usuelles continues - Intervalles de confiance

## De la loi uniforme à la loi exponentielle 

Soit $X$ suivant la loi uniforme $\mathcal{U}$ [0; 1]. On va illustrer par simulation que la variable 
$$y = -\frac{1}{3} \ln(1-X)$$$
suit une loi exponentielle de paramètre 3.

   (i) On souhaite générer un échantillon de $X$ de taille $n = 500$ que l'on stock dans un vecteur $x$. On utilise la fonction runif(n,min=0,max=1) (où r dans `runif` renvoie à `run` pour “tirer”).
```{r}
x = runif(500, min=0,max=1) 
```
   (ii)  On crée ensuite le vecteur $y$ contenant les valeurs de $Y$ associées à $x$. R fait l'opération suivante termes à termes
```{r}
y = -log(1-x)/3 

```
   (iii)  On souhaite superposer l'histogramme des tirages de $Y$ avec la courbe de la densité de la loi exponentielle de paramètre 3. 

           - On trace l'histogramme de $y$: 
```{r}
hist (y, probability=TRUE)
```
(on utilise le paramètre probability-T pour se ramener à une densité et non à l'histogramme en terme d'effectif). 
     
  * Traçons la densité de loi exponentielle de paramètre 3. Commençons par discrétiser les l'axe des abscisses sur [0; 2] avec un pas de 0,1 :
```{r}
discr=seq(0,2,0.1) 

```
  On calcule les valeurs de la densité de la loi exponentielle de paramètre 3 sur cette discrétisation : 
```{r}
exp=dexp (discr,rate=3) # (d dans dexp() signifie density).
```
  
 
  * On ajoute la courbe de la densité de l'exponentielle : 
```{r}
plot(discr,exp)
lines (discr, exp) 
```
    

   (iv) On pourra également comparer les fonctions de répartitions : 
```{r}
plot (ecdf (y)) 
lines (discr, pexp (discr, 3), col="red")  
# (ecdf empirical cumulative distribution function, p dans pexp pour probability function. 
# (fonction de répartition)). 
```
    

 **Remarque 1.1** *On aurait, bien entendu, pu utiliser directement la commande $y=rexp (500,3)$, mais il n'y aurait pas eu d'exercice !* 

## Théorème Central Limit 

On se propose d'observer la convergence en loi de la loi binômiale vers la loi normale : $$\frac{\mathcal{B}(n,p) - np}{\sqrt{np(1-q)}} \rightarrow \mathcal{N}(0,1).$$

On fixe $n$ = 10, $p$ = 0,25.

  (a) On effectue 50000 tirages selon la loi binômiale B(10, 0, 25):
  
```{r}
bin=rbinom (50000, 10,0.25) 
```
  
  (b) On centre et on réduit dans la variable **cr** : 
```{r}
cr=(bin-0.25*10)/sqrt (10*0.25*0.75)
```
 
  (c) On trace: 
```{r}
hist(cr,probability=TRUE) 
```

  (d) On discrétise l'intervalle [-3, 3] pour tracer la densité de la loi normale centrée réduite : 
```{r}
hist(cr,probability=TRUE) 
discr-seq(-3,3,0.01) 
lines (discr, dnorm (discr), col="red") 
```
 
  (ii) On se propose de faire varier les valeurs de n et p par une fonction. Reprenons toutes les lignes précédantes : 
  
```{r}
binnorm=function (n,p) { 
q=1-p 
bin=rbinom (50000,n,p) 
cr=(bin-n*p)/sqrt(n*p*q) 
hist (cr, probability=TRUE) 
discr-seq(-3,3,0.01) 
lines (discr,dnorm(discr), col="red") 
} 
```
  
On peut alors faire tourner la fonction avec différentes valeurs de $n$ et $p$ 

  (iii) On peut recommencer avec les fonctions de répartition : 

```{r}
binnormFDR=function (n,p){
q=1-p 
bin=rbinom (50000,n,p) 
cr=(bin-n*p)/sqrt(n*p*q) 
plot (ecdf (cr)) 
discr-seq(-3,3,0.01) 
lines (discr,pnorm(discr),col="red") 
} 

```

## Lois normales, loi du $\chi^2$, loi de Fisher
On souhaite illustrer les liens entre les lois normales, la loi du $\chi^2$ et la loi de Fisher. 

  (i) On souhaite simuler quatre lois normales centrées réduites indépendantes $X_1$, $X_2$, $X_3$ et $X_4$. 
On génère quatre tirages de 500 : 
```{r}

x1=rnorm(500) 
x2=rnorm(500) 
x3=rnorm(500) 
x4=rnorm (500)
```
 
  (ii) Le théorème du cours annonce que $X_1^2$ + $X_2^2$ + $X_3^2$ + $X_4^2$ suit une loi du $chi^2$ à 4 degrés de liberté. 
La simulation de $X_1^2$ + $X_2^2$ + $X_3^2$ + $X_4^2$ est donnée par 
```{r}
squaresum=x1^2+x2^2+x3^2 +x4^2

```
 
  (iii) On trace la densité de squaresum : 
```{r}
plot(density(squaresum)) 
```
  

  (iv) La densité observée est non nulle sur [0,20]. On discrétise et on compare la densité observée 
à celle de la loi du $\chi_4^2$ : 
```{r}
plot(density(squaresum)) 
discr=seq(0,20,0.1) 
chi=dchisq (discr,4) 
lines(discr, chi, col="red") 
```

On peut également comparer les fonctions de répartition : 
```{r}
plot(ecdf (squaresum)) 
lines(discr,pchisq (discr,4), col="red") 
```


  (v) Un autre résultat dit que le rapport 
$$ \frac{\chi_{d_1}^2 / d_1}{\chi_{d_2}^2 / d_2} \sim \mathcal{F_{d_{1},d_{2}}} $$
=

On se propose de vérifier cette propriété pour $d_1$ = 4 en utilisant les 500 tirages de squaresum et de prendre les valeurs de $d_2$ entre 3 et 10. On initialise. 
```{r}
chi=rchisq (500,3) 
plot (density ((squaresum/4)/(chi/3))) 
lines(discr, df (discr,4,3), col="red") 
```


La commande plot ne peut s'éxécuter qu'une fois sinon, on écrase le graphe précédent. On rajoutera des éléments avec la fonction `lines()`. Prêt pour une boucle for ? 

```{r}
for (i in 4:10){ 
chi=rchisq (500,i)
plot(density(squaresum))
lines (density ((squaresum/4)/(chi/i))) 
lines (discr,df (discr,4,i), col="red") 
}
```
 
On voit que pour des grandes valeurs $d_1$ et $d_2$, la loi de Fisher a une variance qui tend vers 0. Est-ce clair sur votre graphique ? 
 
# Intervalles de confiance 

Dans cette dernière partie du TP, on souhaite illustrer par la simulation la construction de l'intervalle de confiance pour une proportion en suivant les lignes du cours. 

*On considère un stock de rouleaux de câbles de cuivre destiné à la livraison à une entreprise d'installation de lignes téléphoniques. On souhaite estimer la fréquence inconnue p des rouleaux de ce stock ayant une section inférieure à 0,4 mm de diamètre.* 

*On prélève un échantillon aléatoire de 100 rouleaux dans ce stock. Ce stock est assez important pour que l'on puisse assimiler ce prélèvement à un tirage avec remise de 100 rouleaux.* 

*On constate que seuls 4 rouleaux de cet échantillon ont une section inférieure à 0, 4 mm. Ce sont les numéros 30,38,72,81.* 

On va principalement répondre aux questions suivantes. 

* Donner une estimation ponctuelle de la fréquence inconnue $f$ des rouleaux de ce stock ayant une section inférieure à 0,4 mm. 

* Soit $F$ la variable aléatoire qui, à tout échantillon de 100 rouleaux ainsi prélevé dans ce stock, associe la fréquence des rouleaux de cet échantillon ayant une section inférieure à 0,4 mm.

On suppose que $F$ suit la loi normale de moyenne inconnue p et d'écart type$\sqrt{\frac{p(1-p)}{100}}$

    *  Déterminer un intervalle de confiance de la fréquence p avec le coefficient de confiance 95%.
    
    * On considère l'affirmation suivante: “la fréquence p est obligatoirement dans l'intervalle de confiance". 
    
Cette affirmation est-elle vraie ? 

## Construction de l'intervalle de confiance 

### Construction de l'échantillon 

On peut construire le vecteur d'observations des rouleaux défectueux. On fait un vecteur de 100 zéros. 
```{r}
x=rep(0,100) 
```

On remplace les valeurs 30, 38, 72 et 81 par 1.

```{r}
x[c (30,38,72,81)]=1 
```

 

###  Estimation ponctuelle 

L'estimation ponctuelle de la fréquence observée est la moyenne du vecteur x : 
```{r}
f=mean(x) 
```


### Loi X qui compte le nombre de rouleaux défectueux dans le lot de $n$ pièces 

On considère un échantillon de n pièces, on observe donc $X_1,..., X_n$ des variables indépendantes et identiques à 2 issues la réussite (le rouleau est défecteux) avec probabilité $p$ et l'échec. Pour compter, on attribuera donc à $X_i$ la valeur 1 en cas de réussite et 0 sinon. 

La variale $X$ est la somme des $X_i$, 

$$X = \sum_{i=1}^{n} X_i$$ 

La variable X suit une loi binomiale $\mathcal{B}(n, p).$ 

### On pose $f_n = X/n$. Que représente $f_n$ ? 

La variable $f_n$ est l'estimateur de la fréquence de pièces défectueuses. 

### Approximation de $ƒ_n$ 

On suppose que fn peut être approchée par une loi N(m, o) en vertu du théorème central limit. (pour n assez grand). On prendra 
$$ m_n = E(f_n) = E[X/n] = \frac{E(x)}{n} = \frac{np}{n} = p $$
et $$ \sigma_n = \sqrt{Var(f_n)} = \sqrt{Var(X/n)} = \sqrt{\frac{1}{n^2} Var(X)} = \sqrt{\frac{np(1-p)}{n^2}} = \sqrt{\frac{p(1-p)}{n}} = \sqrt{\frac{f(1-f)}{n}}$$

A supposer que $p = f = 0.04$ , on calcule $\sigma_n$ 
```{r}
sigma=sqrt((f*(1-f))/100) 
```


### Risque 5% 

* On cherche a tel que 

$$ P(m_n - a \sigma_n \leq f_n \leq m_n + a \sigma_n ) = 0.95$$ 

On prendra pour valeur de **a** 
```{r}
a=qnorm(0.975) 
```

soit à peu prêt 1,96. 

* Il y a donc un risque de se tromper de probabilité 0,05 si on affirme que 

$$ p - 1,96\sigma_n ≤ f_n ≤ p + 1, 96\sigma_n. $$

* En faisant l'opération $-f_n-p$, puis en multipliant par -1, on déduit qu'au risque 0,05

$$ f - 1,96\sigma_n ≤ p ≤ f + 1, 96\sigma_n.$$ 
### Intervalle de p avec un risque de 5% 
On a donc, au risque 5%, 

$$ f - 1,96\sigma ≤ p ≤ ƒ + 1,96\sigma. $$
Calculons les bornes 
```{r}
binf=f-a*sigma
bsup=f+a*sigma
```

##  Simulations 
On fait l'hypothèse suivante (invérifiable sauf à déballer tous les rouleaux de cuivre). **On suppose que la fréquence estimée $f$ est effectivement correcte.** 

Simulons 1000 valeurs de la variable $X$ associées à 1000 échantillons. 
```{r}
X=rbinom (1000, 100,0.04) 
```

Calculons les valeurs de fn estimées pour chaque réalisation de X: 
```{r}
fn=X/100 
```

### Approximation de fn par une loi normale 
On a approché $F_n$ par une loi normale de paramètres  
$$ m_n = E(f_n) = p,$$ 
et 

   $$ \sigma_n = \sqrt{Var(f_n)} = \sqrt{\frac{f(1-f)}{n}} $$
   
On compare la densité de fn avec une loi normale $\mathcal{N}(f, \sigma_n)$. 
```{r}
plot (density(fn)) 
discr=seq(0,1,0.01) 
lines (discr, dnorm (discr,f,sigma)) 
```


Ce n'est pas très joli, on peut élargie le lissage de la fonction `density()` pour éviter les trous entre groupement de valeurs 
```{r}
plot (density (fn, bw=0.005)) 
discr=seq(0,1,0.01) 
lines (discr, dnorm(discr,f,sigma))
```

 
### Intervalle de confiance 
Cherchons le nombre de valeurs de fn qui sortent de l'intervalle de confiance 2.1.7.

```{r}
sortie = fn [fn<binf | fn>bsup]
```

 
On devrait être aux alentours de 50 valeurs. On devrait même vraiment avoir exactement 50 valeurs. On remarque que ce n'est pas le cas (le plus souvent). Pourquoi ?! 

### Indépendance ? 
Reprenons les lignes de codes pour créer une fonction qui, pour une proportion estimée $p$ et un nombre de simulations N de n tirages nous donnera les simulations en dehors de l'intervalle de confiance. 

```{r}
confiance=function(p,n,N) {
X=rbinom (N,n,p) 
fn=X/n 
sigma=sqrt((p* (1-p))/n) 
binf=p-1.96*sigma 
bsup=p+1.96*sigma 
sortie=fn [fn<binf | fn>bsup] 
return(sortie) 
}
```

 
On peut jouer avec notre fonction, tester des valeurs de $p, n, N$. On s'aperçoit que quelque-soit la valeur de $p$, même centrale, quelque-soit la valeur de $N$ et de $n$, on ne récupère pas toujours 5% de $N$ valeurs. 

C'est assez troublant puisqu'on a construit un intervalle de confiance à 5% qui devrait être assez fiable. En réalité (pour avoir fait enchaîner des lancers de pièces en amphi quand on pouvait encore le faire), je n'ai jamais été mis en défaut. 
On peut avancer une explication: la machine a du mal à produire des tirages totalement indépendants. Il faut bien avoir conscience que l'aléa et l'indépendance sont des choses compliquées dans l'électronique. 

Il y a fort à parier que si nous mettons en commun chacun une série de 10 simulations, 5% seront en dehors de l'intervalle. En multipliant les machines, nous devrions retrouver l'indépendance nécessaire. 


   